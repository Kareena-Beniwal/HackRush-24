{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8400/8400 [00:00<00:00, 13483.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 32, 250) (8400,)\n"
     ]
    }
   ],
   "source": [
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
    "\n",
    "all_blocks = []\n",
    "all_labels = []\n",
    "\n",
    "all_files_path = natsorted(glob('merged_data_pkl/*'))\n",
    "\n",
    "for path in tqdm(all_files_path):\n",
    "    with open(path, 'rb') as file:\n",
    "        data_dict = pickle.load(file)\n",
    "        all_blocks.append(data_dict['data'])\n",
    "        all_labels.append(data_dict['label'])\n",
    "\n",
    "X = np.array(all_blocks)\n",
    "Y = np.array(all_labels)\n",
    "\n",
    "print(X.shape, Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "X_data_files  = natsorted(glob('./train_pkl/train_data_person_*_data.pkl'))\n",
    "Y_label_files = natsorted(glob('./train_pkl/train_data_person_*_label.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class SoundCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoundCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 4 * 31, 512)  # Corrected dimension\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)  # Assuming 10 different classes\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to include channel dimension (1, 32, 250)\n",
    "X = X.reshape(X.shape[0], 1, 32, 250)\n",
    "\n",
    "Y = Y.astype(np.int64)\n",
    "\n",
    "\n",
    "# Convert to torch tensors\n",
    "tensor_X = torch.Tensor(X)  # transform to torch tensor\n",
    "tensor_Y = torch.Tensor(Y)\n",
    "\n",
    "# Create your dataloader\n",
    "my_dataset = TensorDataset(tensor_X, tensor_Y)\n",
    "train_loader = DataLoader(my_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SomeModelDefinition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/project/new/ensemble.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/ensemble.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSaved better model at epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with validation accuracy: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m}\u001b[39;00m\u001b[39m%.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/ensemble.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/ensemble.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m model \u001b[39m=\u001b[39m SomeModelDefinition()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/ensemble.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m criterion \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/ensemble.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SomeModelDefinition' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the device globally\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def validation_accuracy(model, val_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total  # Correct percentage calculation\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, save_path, device):\n",
    "    model.to(device)  # Ensure model is on the right device\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        val_acc = validation_accuracy(model, val_loader, device)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}, Validation Accuracy: {val_acc}%')\n",
    "        \n",
    "        if val_acc > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            torch.save(model.state_dict(), save_path)  # Save only state dict for efficiency\n",
    "            print(f'Saved better model at epoch {epoch + 1} with validation accuracy: {val_acc}%.')\n",
    "\n",
    "# Example usage\n",
    "for i in range(10):\n",
    "    model = SoundCNN()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    save_path = 'path_to_save_model.pth'\n",
    "\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, save_path=save_path, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 02:09:17.862882: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/95\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 2s/step - accuracy: 0.1250 - loss: 4.2142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713040758.824874 1214382 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - accuracy: 0.1548 - loss: 3.5135 - val_accuracy: 0.2381 - val_loss: 2.0071\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.2866 - loss: 1.8770 - val_accuracy: 0.2751 - val_loss: 1.8637\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.3879 - loss: 1.6945 - val_accuracy: 0.3254 - val_loss: 1.8476\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.4802 - loss: 1.4680 - val_accuracy: 0.3386 - val_loss: 1.7433\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.5609 - loss: 1.2451 - val_accuracy: 0.3571 - val_loss: 1.7598\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.6806 - loss: 0.9723 - val_accuracy: 0.3862 - val_loss: 1.9332\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.7473 - loss: 0.7421 - val_accuracy: 0.3743 - val_loss: 2.1354\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.8701 - loss: 0.4595 - val_accuracy: 0.3902 - val_loss: 2.2452\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.9407 - loss: 0.2365 - val_accuracy: 0.3836 - val_loss: 2.3740\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.9849 - loss: 0.0997 - val_accuracy: 0.4008 - val_loss: 2.8166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.1225 - loss: 3.7341 - val_accuracy: 0.1402 - val_loss: 2.1607\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.1884 - loss: 2.1049 - val_accuracy: 0.1918 - val_loss: 2.1028\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.2562 - loss: 1.9912 - val_accuracy: 0.2024 - val_loss: 2.0875\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.3425 - loss: 1.7961 - val_accuracy: 0.2791 - val_loss: 1.9336\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.4727 - loss: 1.5074 - val_accuracy: 0.2698 - val_loss: 1.9715\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.5869 - loss: 1.2447 - val_accuracy: 0.3214 - val_loss: 2.0029\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.6951 - loss: 0.9053 - val_accuracy: 0.3347 - val_loss: 1.9655\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.8091 - loss: 0.6091 - val_accuracy: 0.3241 - val_loss: 2.3026\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.9127 - loss: 0.3452 - val_accuracy: 0.3122 - val_loss: 2.9019\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.9053 - loss: 0.3428 - val_accuracy: 0.3175 - val_loss: 3.0714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 122ms/step - accuracy: 0.1361 - loss: 2.9839 - val_accuracy: 0.2315 - val_loss: 1.9295\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.2895 - loss: 1.8468 - val_accuracy: 0.2989 - val_loss: 1.7924\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.4003 - loss: 1.5634 - val_accuracy: 0.3862 - val_loss: 1.5353\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.5085 - loss: 1.3391 - val_accuracy: 0.4339 - val_loss: 1.4929\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.5815 - loss: 1.1126 - val_accuracy: 0.4193 - val_loss: 1.5659\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.6848 - loss: 0.8801 - val_accuracy: 0.4683 - val_loss: 1.4887\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.7983 - loss: 0.6019 - val_accuracy: 0.4696 - val_loss: 1.5623\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.8733 - loss: 0.4080 - val_accuracy: 0.4749 - val_loss: 1.6486\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.9336 - loss: 0.2571 - val_accuracy: 0.4854 - val_loss: 1.8317\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.9601 - loss: 0.1634 - val_accuracy: 0.4762 - val_loss: 1.9512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 121ms/step - accuracy: 0.1565 - loss: 34.6970 - val_accuracy: 0.2037 - val_loss: 2.0352\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.2554 - loss: 1.9567 - val_accuracy: 0.2500 - val_loss: 1.9537\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.3383 - loss: 1.7918 - val_accuracy: 0.2619 - val_loss: 1.9051\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.3904 - loss: 1.6307 - val_accuracy: 0.2831 - val_loss: 1.8809\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.4895 - loss: 1.4319 - val_accuracy: 0.3029 - val_loss: 1.9151\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.5491 - loss: 1.2509 - val_accuracy: 0.2923 - val_loss: 1.9938\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.6293 - loss: 1.0423 - val_accuracy: 0.2738 - val_loss: 2.1970\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.7056 - loss: 0.8874 - val_accuracy: 0.2897 - val_loss: 2.2702\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.8026 - loss: 0.6587 - val_accuracy: 0.2725 - val_loss: 2.5528\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.8165 - loss: 0.6299 - val_accuracy: 0.2421 - val_loss: 3.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - accuracy: 0.1444 - loss: 8.2417 - val_accuracy: 0.2024 - val_loss: 2.1649\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.2153 - loss: 2.1855 - val_accuracy: 0.1892 - val_loss: 2.1486\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.2202 - loss: 2.0932 - val_accuracy: 0.1944 - val_loss: 2.1147\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.2301 - loss: 2.0233 - val_accuracy: 0.1997 - val_loss: 2.2208\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.2252 - loss: 2.1293 - val_accuracy: 0.2011 - val_loss: 2.3616\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.2771 - loss: 1.9473 - val_accuracy: 0.1971 - val_loss: 2.1355\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.3099 - loss: 1.8915 - val_accuracy: 0.2063 - val_loss: 2.1690\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.3692 - loss: 1.7396 - val_accuracy: 0.2288 - val_loss: 2.2085\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.4336 - loss: 1.6080 - val_accuracy: 0.2460 - val_loss: 2.2664\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.5129 - loss: 1.4636 - val_accuracy: 0.2487 - val_loss: 2.2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - accuracy: 0.1194 - loss: 3.3430 - val_accuracy: 0.1561 - val_loss: 2.1834\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.1734 - loss: 2.1617 - val_accuracy: 0.2011 - val_loss: 2.1215\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.2614 - loss: 2.0329 - val_accuracy: 0.2513 - val_loss: 2.0480\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - accuracy: 0.3453 - loss: 1.8388 - val_accuracy: 0.2619 - val_loss: 2.0436\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.4231 - loss: 1.6298 - val_accuracy: 0.2698 - val_loss: 2.0569\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 108ms/step - accuracy: 0.5069 - loss: 1.4179 - val_accuracy: 0.2672 - val_loss: 2.2165\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.6174 - loss: 1.1521 - val_accuracy: 0.2685 - val_loss: 2.3013\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.7311 - loss: 0.8321 - val_accuracy: 0.2963 - val_loss: 2.6461\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.8600 - loss: 0.5096 - val_accuracy: 0.2566 - val_loss: 3.0502\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.9386 - loss: 0.2657 - val_accuracy: 0.2712 - val_loss: 3.3232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 122ms/step - accuracy: 0.1193 - loss: 3.9385 - val_accuracy: 0.1892 - val_loss: 2.1364\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.2280 - loss: 2.0697 - val_accuracy: 0.2288 - val_loss: 2.0140\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.2870 - loss: 1.8707 - val_accuracy: 0.2659 - val_loss: 1.8884\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.4075 - loss: 1.6054 - val_accuracy: 0.3320 - val_loss: 1.6588\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.5297 - loss: 1.2443 - val_accuracy: 0.3823 - val_loss: 1.5420\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.6564 - loss: 0.9478 - val_accuracy: 0.4484 - val_loss: 1.4778\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.7431 - loss: 0.7190 - val_accuracy: 0.4206 - val_loss: 1.5694\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.8362 - loss: 0.5128 - val_accuracy: 0.4656 - val_loss: 1.6787\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.9135 - loss: 0.3027 - val_accuracy: 0.4339 - val_loss: 1.7725\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.9638 - loss: 0.1761 - val_accuracy: 0.4709 - val_loss: 2.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 121ms/step - accuracy: 0.1295 - loss: 3.0971 - val_accuracy: 0.1389 - val_loss: 2.1938\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 106ms/step - accuracy: 0.1708 - loss: 2.1657 - val_accuracy: 0.1640 - val_loss: 2.1535\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 107ms/step - accuracy: 0.2028 - loss: 2.1037 - val_accuracy: 0.1759 - val_loss: 2.0934\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.3082 - loss: 1.9163 - val_accuracy: 0.2632 - val_loss: 1.9070\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.4121 - loss: 1.6339 - val_accuracy: 0.3016 - val_loss: 1.8827\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 110ms/step - accuracy: 0.5300 - loss: 1.3145 - val_accuracy: 0.3360 - val_loss: 1.8200\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.6671 - loss: 0.9723 - val_accuracy: 0.3386 - val_loss: 1.9592\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.7915 - loss: 0.6744 - val_accuracy: 0.3373 - val_loss: 2.1221\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.8756 - loss: 0.4138 - val_accuracy: 0.3770 - val_loss: 2.1329\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.9509 - loss: 0.1965 - val_accuracy: 0.3690 - val_loss: 2.6356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 124ms/step - accuracy: 0.1591 - loss: 3.3907 - val_accuracy: 0.2937 - val_loss: 1.8837\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - accuracy: 0.3311 - loss: 1.7765 - val_accuracy: 0.3995 - val_loss: 1.6736\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 117ms/step - accuracy: 0.4673 - loss: 1.4693 - val_accuracy: 0.4458 - val_loss: 1.5353\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.5352 - loss: 1.2435 - val_accuracy: 0.4392 - val_loss: 1.5911\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.6512 - loss: 1.0053 - val_accuracy: 0.4206 - val_loss: 1.6635\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.7437 - loss: 0.7523 - val_accuracy: 0.4431 - val_loss: 1.7576\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.8287 - loss: 0.5341 - val_accuracy: 0.4696 - val_loss: 1.8719\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.8982 - loss: 0.3280 - val_accuracy: 0.4312 - val_loss: 2.0842\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.9595 - loss: 0.1776 - val_accuracy: 0.4352 - val_loss: 2.3133\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.9672 - loss: 0.1344 - val_accuracy: 0.4392 - val_loss: 2.6969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 128ms/step - accuracy: 0.1442 - loss: 3.6580 - val_accuracy: 0.1733 - val_loss: 2.1464\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.2306 - loss: 2.0642 - val_accuracy: 0.3042 - val_loss: 1.8183\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.4187 - loss: 1.6425 - val_accuracy: 0.3505 - val_loss: 1.7749\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.4892 - loss: 1.4524 - val_accuracy: 0.3942 - val_loss: 1.6218\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 111ms/step - accuracy: 0.5606 - loss: 1.2171 - val_accuracy: 0.3929 - val_loss: 1.7112\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.6469 - loss: 0.9956 - val_accuracy: 0.4193 - val_loss: 1.7298\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 109ms/step - accuracy: 0.7103 - loss: 0.8246 - val_accuracy: 0.3981 - val_loss: 1.8317\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.8299 - loss: 0.5631 - val_accuracy: 0.4008 - val_loss: 2.0023\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 118ms/step - accuracy: 0.9034 - loss: 0.3306 - val_accuracy: 0.4074 - val_loss: 2.2236\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 114ms/step - accuracy: 0.9681 - loss: 0.1558 - val_accuracy: 0.4034 - val_loss: 2.5848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
    "\n",
    "# Assuming X_data_files and Y_label_files are defined somewhere above this block\n",
    "index = 0\n",
    "for X_data_path, Y_label_path in zip(X_data_files, Y_label_files):\n",
    "    filename = os.path.splitext(os.path.basename(X_data_path))[0].split('_')[-2]\n",
    "    \n",
    "    with open(X_data_path, 'rb') as file:\n",
    "        X_data = pickle.load(file)\n",
    "    with open(Y_label_path, 'rb') as file:\n",
    "        Y_label = pickle.load(file)\n",
    "\n",
    "    all_blocks = []\n",
    "    all_labels = [] \n",
    "\n",
    "    skip_window_size = 32\n",
    "    label_cnt = 0\n",
    "\n",
    "    for idx in range(0, X_data.shape[0], skip_window_size):\n",
    "        data_frame = X_data[idx:idx+skip_window_size, :]\n",
    "        \n",
    "        skip_frame_size = 50\n",
    "\n",
    "        for frame_idx in range(0, data_frame.shape[1], skip_frame_size):\n",
    "            if frame_idx != 0:\n",
    "                data_chunk = data_frame[:, max(0, frame_idx-25):frame_idx+skip_frame_size]\n",
    "            else:\n",
    "                data_chunk = data_frame[:, frame_idx:frame_idx+skip_frame_size+25]\n",
    "            \n",
    "            all_blocks.append(data_chunk)\n",
    "            all_labels.append(Y_label[label_cnt])\n",
    "        \n",
    "        label_cnt += 1\n",
    "        \n",
    "    X = np.array(all_blocks)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)  # Reshaping for Conv2D input\n",
    "    y = np.array(all_labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the CNN model\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(np.unique(y).size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save(f'ensemble_models/trained_cnn_model_{index}.h5')\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "to19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
