{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (36680, 32, 250)\n",
      "Shape of Y: (36680,)\n",
      "Summary Statistics of Y:\n",
      "Min: 1\n",
      "Max: 28\n",
      "Mean: 14.5\n",
      "Median: 14.5\n",
      "Standard Deviation: 8.077747210701755\n",
      "Class Counts:\n",
      "Class 1: 1310 instances\n",
      "Class 2: 1310 instances\n",
      "Class 3: 1310 instances\n",
      "Class 4: 1310 instances\n",
      "Class 5: 1310 instances\n",
      "Class 6: 1310 instances\n",
      "Class 7: 1310 instances\n",
      "Class 8: 1310 instances\n",
      "Class 9: 1310 instances\n",
      "Class 10: 1310 instances\n",
      "Class 11: 1310 instances\n",
      "Class 12: 1310 instances\n",
      "Class 13: 1310 instances\n",
      "Class 14: 1310 instances\n",
      "Class 15: 1310 instances\n",
      "Class 16: 1310 instances\n",
      "Class 17: 1310 instances\n",
      "Class 18: 1310 instances\n",
      "Class 19: 1310 instances\n",
      "Class 20: 1310 instances\n",
      "Class 21: 1310 instances\n",
      "Class 22: 1310 instances\n",
      "Class 23: 1310 instances\n",
      "Class 24: 1310 instances\n",
      "Class 25: 1310 instances\n",
      "Class 26: 1310 instances\n",
      "Class 27: 1310 instances\n",
      "Class 28: 1310 instances\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# # Load the data from the NPZ file\n",
    "data = np.load('data.npz')\n",
    "\n",
    "# Assign X and Y from the loaded data\n",
    "X = data['X']\n",
    "Y = data['Y'].astype(np.int32)\n",
    "\n",
    "# Optionally, check shapes of the loaded arrays\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of Y:\", Y.shape)\n",
    "\n",
    "# Assuming Y is your numpy array\n",
    "print(\"Summary Statistics of Y:\")\n",
    "print(\"Min:\", np.min(Y))\n",
    "print(\"Max:\", np.max(Y))\n",
    "print(\"Mean:\", np.mean(Y))\n",
    "print(\"Median:\", np.median(Y))\n",
    "print(\"Standard Deviation:\", np.std(Y))\n",
    "\n",
    "# For classification tasks, it might also be useful to see the distribution of classes:\n",
    "if np.issubdtype(Y.dtype, np.integer):  # Check if Y contains integer (class labels typically are integers)\n",
    "    print(\"Class Counts:\")\n",
    "    unique, counts = np.unique(Y, return_counts=True)\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"Class {label}: {count} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remapped Y:\n",
      "[0 0 0 ... 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming Y is your numpy array containing labels\n",
    "label_map = {\n",
    "    1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 2, 8: 2, 9: 2,\n",
    "    10: 3, 11: 3, 12: 3, 13: 4, 14: 4, 15: 4, 16: 6, 17: 5,\n",
    "    18: 5, 19: 5, 20: 6, 21: 6, 22: 6, 23: 7, 24: 7, 25: 7,\n",
    "    26: 8, 27: 8, 28: 8\n",
    "}\n",
    "\n",
    "# Find the maximum label to create a sufficiently large mapping array\n",
    "max_label = max(label_map.keys())\n",
    "\n",
    "# Create an array that will hold the new labels\n",
    "# Initialize it with zeros or another default value that indicates unmapped labels if there are any\n",
    "new_labels = np.zeros(max_label + 1, dtype=int)  # plus 1 because NumPy arrays are 0-indexed\n",
    "\n",
    "# Fill in the new_labels array with mapped values\n",
    "for key, value in label_map.items():\n",
    "    new_labels[key] = value\n",
    "\n",
    "# Remap Y using the new_labels array\n",
    "# Here, Y values must be within the range of label_map keys; otherwise, you need to handle potential out-of-bound indices\n",
    "Y= new_labels[Y]\n",
    "\n",
    "# If you want to check or display the remapped array\n",
    "\n",
    "print(\"Remapped Y:\")\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoundCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 4 * 31, 512)  # Corrected dimension\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)  # Assuming 10 different classes\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to include channel dimension (1, 32, 250)\n",
    "X = X.reshape(X.shape[0], 1, 32, 375)\n",
    "\n",
    "Y = Y.astype(np.int64)\n",
    "\n",
    "\n",
    "# Convert to torch tensors\n",
    "tensor_X = torch.Tensor(X)  # transform to torch tensor\n",
    "tensor_Y = torch.Tensor(Y)\n",
    "\n",
    "# Create your dataloader\n",
    "my_dataset = TensorDataset(tensor_X, tensor_Y)\n",
    "train_loader = DataLoader(my_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoundCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Assuming tensor_X and tensor_Y are already defined\n",
    "dataset = TensorDataset(tensor_X, tensor_Y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(model, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    model.train()  # Set the model back to train mode\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X = torch.Tensor(X)  # Assuming X is your input data.\n",
    "tensor_Y = torch.Tensor(Y).long()  # Convert labels to long\n",
    "\n",
    "# Create dataset\n",
    "my_dataset = TensorDataset(tensor_X, tensor_Y)\n",
    "train_size = int(0.8 * len(my_dataset))\n",
    "val_size = len(my_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(my_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2820223229643046, Validation Accuracy: 16.534896401308615%\n",
      "Saved better model at epoch 1 with validation accuracy: 16.534896401308615%.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/project/new/kareena copy.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/kareena%20copy.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m save_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./SoundCNN_model.pth\u001b[39m\u001b[39m'\u001b[39m  \u001b[39m# Modify path as needed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/kareena%20copy.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Call training function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/kareena%20copy.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m train_model(model, train_loader, val_loader, criterion, optimizer, \u001b[39m18\u001b[39;49m, save_path)\n",
      "\u001b[1;32m/home/project/new/kareena copy.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/kareena%20copy.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/kareena%20copy.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/kareena%20copy.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/kareena%20copy.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.0.116.136/home/project/new/kareena%20copy.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/to19/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/to19/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, save_path):\n",
    "    model.train()\n",
    "    best_accuracy = 0.0  # To track the best model\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        val_acc = validation_accuracy(model, val_loader)\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}, Validation Accuracy: {val_acc}%')\n",
    "        \n",
    "        # Save the best model if the current model is better\n",
    "        if val_acc > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': running_loss,\n",
    "                'accuracy': val_acc\n",
    "            }, save_path)\n",
    "            print(f'Saved better model at epoch {epoch+1} with validation accuracy: {val_acc}%.')\n",
    "\n",
    "# Define model, criterion, optimizer, and file path for saving the model\n",
    "model = SoundCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "save_path = 'SoundCNN_model.pth'  # Modify path as needed\n",
    "\n",
    "# Call training function\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, 18, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel('/home/project/new/Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1249214/2964036573.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  X_test_blocks = torch.tensor(all_test_blocks, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Assuming `test_data` is already loaded and is a Pandas DataFrame\n",
    "all_test_blocks = []\n",
    "block_height = 32\n",
    "num_columns_in_test = 750  # Columns per test block\n",
    "\n",
    "# Iterate over the dataset in chunks of 32 rows\n",
    "for start_row in range(0, test_data.shape[0], block_height):\n",
    "    if start_row + block_height > test_data.shape[0]:\n",
    "        continue  # Skip incomplete blocks\n",
    "    chunk = test_data.iloc[start_row:start_row + block_height]\n",
    "\n",
    "    # Split each 750-column block into three 250-column blocks\n",
    "    for i in range(2):  # Since 750/250 = 3\n",
    "        start_col = i * 375\n",
    "        end_col = start_col + 375\n",
    "        block = chunk.iloc[:, start_col:end_col]\n",
    "        all_test_blocks.append(block.values.reshape(1, block_height, 375))  # Adding channel dimension\n",
    "\n",
    "# Convert blocks to PyTorch tensors\n",
    "X_test_blocks = torch.tensor(all_test_blocks, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoundCNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=7936, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming the model is already defined as `SoundCNN`\n",
    "model = SoundCNN()\n",
    "model.load_state_dict(torch.load('/home/project/new/SoundCNN_model.pth')['model_state_dict'])\n",
    "\n",
    "# Transfer model to appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_blocks = X_test_blocks.to(device)  # Move the test data to the same device as the model\n",
    "with torch.no_grad():  # Ensure no gradients are computed during inference\n",
    "    predictions = model(X_test_blocks)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1).cpu().numpy()  # Move predictions back to CPU and convert to numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# `predicted_classes` is the numpy array containing the class indices predicted by the model\n",
    "predictions_df = pd.DataFrame(predicted_classes, columns=['PredictedClass'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path and name of the CSV file\n",
    "csv_file_path = './predictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file without the index column\n",
    "predictions_df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: \"Tiger\",\n",
    "    1: \"Snake\",\n",
    "    2: \"Wolf\",\n",
    "    3: \"Bear\",\n",
    "    4: \"Rabbit\",\n",
    "    5: \"Monkey\",\n",
    "    6: \"Eagle\",\n",
    "    7: \"Dolphin\",\n",
    "    8: \"Koala\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `predicted_classes` is already available as a numpy array\n",
    "predictions_df = pd.DataFrame(predicted_classes, columns=['PredictedClass'])\n",
    "\n",
    "# Replace numeric labels with animal names using the mapping\n",
    "predictions_df['PredictedClass'] = predictions_df['PredictedClass'].replace(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path and name of the CSV file\n",
    "csv_file_path = './animal_predictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file without the index column\n",
    "predictions_df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Load predictions\n",
    "predictions_df = pd.read_csv('./animal_predictions.csv')\n",
    "\n",
    "# Function to determine the majority or random in case of a tie\n",
    "def majority_or_random(labels):\n",
    "    count = Counter(labels)\n",
    "    max_freq = max(count.values())\n",
    "    candidates = [label for label, freq in count.items() if freq == max_freq]\n",
    "    return random.choice(candidates)\n",
    "\n",
    "# Group predictions in groups of 3 and apply the function\n",
    "grouped_labels = []\n",
    "for i in range(0, len(predictions_df), 2):\n",
    "    labels = predictions_df['PredictedClass'][i:i+2].tolist()\n",
    "    if len(labels) == 2:  # Ensure it's a full group of 2\n",
    "        grouped_label = majority_or_random(labels)\n",
    "        grouped_labels.append(grouped_label)\n",
    "\n",
    "# Create new DataFrame\n",
    "final_predictions_df = pd.DataFrame(grouped_labels, columns=['MajorityVotedClass'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "final_csv_file_path = './final_animal_predictions.csv'\n",
    "final_predictions_df.to_csv(final_csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './final_animal_predictions.csv'\n",
    "predictions_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the 'ID' column\n",
    "predictions_df['ID'] = ['id_' + str(index + 1) for index in predictions_df.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to make 'ID' the first column\n",
    "column_order = ['ID', 'MajorityVotedClass']\n",
    "predictions_df = predictions_df[column_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "updated_csv_file_path = './updated_final_animal_predictions.csv'\n",
    "predictions_df.to_csv(updated_csv_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "to19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
