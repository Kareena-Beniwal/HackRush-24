{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4190/8400 [00:00<00:00, 20810.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8400/8400 [00:00<00:00, 19775.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 32, 250) (8400,)\n"
     ]
    }
   ],
   "source": [
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D\n",
    "\n",
    "all_blocks = []\n",
    "all_labels = []\n",
    "\n",
    "all_files_path = natsorted(glob('merged_data_pkl/*'))\n",
    "\n",
    "for path in tqdm(all_files_path):\n",
    "    with open(path, 'rb') as file:\n",
    "        data_dict = pickle.load(file)\n",
    "        all_blocks.append(data_dict['data'])\n",
    "        all_labels.append(data_dict['label'])\n",
    "\n",
    "X = np.array(all_blocks)\n",
    "Y = np.array(all_labels)\n",
    "\n",
    "print(X.shape, Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SoundCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 4 * 31, 512)  # Corrected dimension\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)  # Assuming 10 different classes\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to include channel dimension (1, 32, 250)\n",
    "X = X.reshape(X.shape[0], 1, 32, 250)\n",
    "\n",
    "Y = Y.astype(np.int64)\n",
    "\n",
    "\n",
    "# Convert to torch tensors\n",
    "tensor_X = torch.Tensor(X)  # transform to torch tensor\n",
    "tensor_Y = torch.Tensor(Y)\n",
    "\n",
    "# Create your dataloader\n",
    "my_dataset = TensorDataset(tensor_X, tensor_Y)\n",
    "train_loader = DataLoader(my_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoundCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Assuming tensor_X and tensor_Y are already defined\n",
    "dataset = TensorDataset(tensor_X, tensor_Y)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(model, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    model.train()  # Set the model back to train mode\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X = torch.Tensor(X)  # Assuming X is your input data.\n",
    "tensor_Y = torch.Tensor(Y).long()  # Convert labels to long\n",
    "\n",
    "# Create dataset\n",
    "my_dataset = TensorDataset(tensor_X, tensor_Y)\n",
    "train_size = int(0.8 * len(my_dataset))\n",
    "val_size = len(my_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(my_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.507578534171695, Validation Accuracy: 14.166666666666666%\n",
      "Saved better model at epoch 1 with validation accuracy: 14.166666666666666%.\n",
      "Epoch 2, Loss: 2.1743020103091286, Validation Accuracy: 15.297619047619047%\n",
      "Saved better model at epoch 2 with validation accuracy: 15.297619047619047%.\n",
      "Epoch 3, Loss: 2.1548023927779423, Validation Accuracy: 14.107142857142858%\n",
      "Epoch 4, Loss: 2.1738751888275147, Validation Accuracy: 18.392857142857142%\n",
      "Saved better model at epoch 4 with validation accuracy: 18.392857142857142%.\n",
      "Epoch 5, Loss: 2.1567490941002254, Validation Accuracy: 16.785714285714285%\n",
      "Epoch 6, Loss: 2.1324926580701558, Validation Accuracy: 19.166666666666668%\n",
      "Saved better model at epoch 6 with validation accuracy: 19.166666666666668%.\n",
      "Epoch 7, Loss: 2.141413727260771, Validation Accuracy: 14.94047619047619%\n",
      "Epoch 8, Loss: 2.2157293910071965, Validation Accuracy: 15.833333333333334%\n",
      "Epoch 9, Loss: 2.1550103051321847, Validation Accuracy: 15.892857142857142%\n",
      "Epoch 10, Loss: 2.138664481753395, Validation Accuracy: 16.25%\n",
      "Epoch 11, Loss: 2.1022329387210665, Validation Accuracy: 16.30952380952381%\n",
      "Epoch 12, Loss: 2.086806371098473, Validation Accuracy: 14.345238095238095%\n",
      "Epoch 13, Loss: 1.9894686608087448, Validation Accuracy: 14.880952380952381%\n",
      "Epoch 14, Loss: 1.867341601280939, Validation Accuracy: 14.583333333333334%\n",
      "Epoch 15, Loss: 1.6433997983024233, Validation Accuracy: 14.523809523809524%\n",
      "Epoch 16, Loss: 1.6278455586660476, Validation Accuracy: 13.988095238095237%\n",
      "Epoch 17, Loss: 1.1393013363792783, Validation Accuracy: 14.107142857142858%\n",
      "Epoch 18, Loss: 0.6556560998871213, Validation Accuracy: 15.357142857142858%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, save_path):\n",
    "    model.train()\n",
    "    best_accuracy = 0.0  # To track the best model\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        val_acc = validation_accuracy(model, val_loader)\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}, Validation Accuracy: {val_acc}%')\n",
    "        \n",
    "        # Save the best model if the current model is better\n",
    "        if val_acc > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': running_loss,\n",
    "                'accuracy': val_acc\n",
    "            }, save_path)\n",
    "            print(f'Saved better model at epoch {epoch+1} with validation accuracy: {val_acc}%.')\n",
    "\n",
    "# Define model, criterion, optimizer, and file path for saving the model\n",
    "model = SoundCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "save_path = './SoundCNN_model.pth'  # Modify path as needed\n",
    "\n",
    "# Call training function\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, 18, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel('/home/project/new/Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Assuming `test_data` is already loaded and is a Pandas DataFrame\n",
    "all_test_blocks = []\n",
    "block_height = 32\n",
    "num_columns_in_test = 750  # Columns per test block\n",
    "\n",
    "# Iterate over the dataset in chunks of 32 rows\n",
    "for start_row in range(0, test_data.shape[0], block_height):\n",
    "    if start_row + block_height > test_data.shape[0]:\n",
    "        continue  # Skip incomplete blocks\n",
    "    chunk = test_data.iloc[start_row:start_row + block_height]\n",
    "\n",
    "    # Split each 750-column block into three 250-column blocks\n",
    "    for i in range(3):  # Since 750/250 = 3\n",
    "        start_col = i * 250\n",
    "        end_col = start_col + 250\n",
    "        block = chunk.iloc[:, start_col:end_col]\n",
    "        all_test_blocks.append(block.values.reshape(1, block_height, 250))  # Adding channel dimension\n",
    "\n",
    "# Convert blocks to PyTorch tensors\n",
    "X_test_blocks = torch.tensor(all_test_blocks, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoundCNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=7936, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming the model is already defined as `SoundCNN`\n",
    "model = SoundCNN()\n",
    "model.load_state_dict(torch.load('/home/project/new/SoundCNN_model.pth')['model_state_dict'])\n",
    "\n",
    "# Transfer model to appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_blocks = X_test_blocks.to(device)  # Move the test data to the same device as the model\n",
    "with torch.no_grad():  # Ensure no gradients are computed during inference\n",
    "    predictions = model(X_test_blocks)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1).cpu().numpy()  # Move predictions back to CPU and convert to numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# `predicted_classes` is the numpy array containing the class indices predicted by the model\n",
    "predictions_df = pd.DataFrame(predicted_classes, columns=['PredictedClass'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path and name of the CSV file\n",
    "csv_file_path = './predictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file without the index column\n",
    "predictions_df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: \"Tiger\",\n",
    "    1: \"Snake\",\n",
    "    2: \"Wolf\",\n",
    "    3: \"Bear\",\n",
    "    4: \"Rabbit\",\n",
    "    5: \"Monkey\",\n",
    "    6: \"Eagle\",\n",
    "    7: \"Dolphin\",\n",
    "    8: \"Koala\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming `predicted_classes` is already available as a numpy array\n",
    "predictions_df = pd.DataFrame(predicted_classes, columns=['PredictedClass'])\n",
    "\n",
    "# Replace numeric labels with animal names using the mapping\n",
    "predictions_df['PredictedClass'] = predictions_df['PredictedClass'].replace(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path and name of the CSV file\n",
    "csv_file_path = './animal_predictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file without the index column\n",
    "predictions_df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Load predictions\n",
    "predictions_df = pd.read_csv('./animal_predictions.csv')\n",
    "\n",
    "# Function to determine the majority or random in case of a tie\n",
    "def majority_or_random(labels):\n",
    "    count = Counter(labels)\n",
    "    max_freq = max(count.values())\n",
    "    candidates = [label for label, freq in count.items() if freq == max_freq]\n",
    "    return random.choice(candidates)\n",
    "\n",
    "# Group predictions in groups of 3 and apply the function\n",
    "grouped_labels = []\n",
    "for i in range(0, len(predictions_df), 3):\n",
    "    labels = predictions_df['PredictedClass'][i:i+3].tolist()\n",
    "    if len(labels) == 3:  # Ensure it's a full group of 3\n",
    "        grouped_label = majority_or_random(labels)\n",
    "        grouped_labels.append(grouped_label)\n",
    "\n",
    "# Create new DataFrame\n",
    "final_predictions_df = pd.DataFrame(grouped_labels, columns=['MajorityVotedClass'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "final_csv_file_path = './final_animal_predictions.csv'\n",
    "final_predictions_df.to_csv(final_csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './final_animal_predictions.csv'\n",
    "predictions_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the 'ID' column\n",
    "predictions_df['ID'] = ['id_' + str(index + 1) for index in predictions_df.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to make 'ID' the first column\n",
    "column_order = ['ID', 'MajorityVotedClass']\n",
    "predictions_df = predictions_df[column_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "updated_csv_file_path = './updated_final_animal_predictions.csv'\n",
    "predictions_df.to_csv(updated_csv_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "to19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
